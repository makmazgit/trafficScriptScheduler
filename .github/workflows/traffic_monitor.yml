name: Traffic Monitor

on:
  schedule:
    - cron: '*/5 * * * *'  # Run every 5 minutes
  workflow_dispatch:  # Manual trigger
    inputs:
      debug_enabled:
        type: boolean
        description: 'Run the workflow with debug logging'
        required: false
        default: false

permissions:
  contents: read
  actions: write

jobs:
  collect-traffic-data:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'schedule'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Download previous database
      continue-on-error: true  # Continue if this is the first run and no previous artifact exists
      uses: actions/download-artifact@v4
      with:
        name: route-data
        path: previous-data
        
    - name: Restore previous database
      run: |
        mkdir -p database backups
        if [ -f "previous-data/database/routes.db" ]; then
          cp previous-data/database/routes.db database/routes.db
          echo "Restored previous database"
        else
          echo "No previous database found, will create new one"
        fi
    
    - name: Wait random delay
      run: |
        sleep $(( RANDOM % 30 ))  # Random delay 0-30 seconds to avoid exact timing conflicts
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Create necessary directories and initialize database
      run: |
        mkdir -p logs
        python -c "
        from src.database.models import Base, engine
        Base.metadata.create_all(engine)
        print('Database initialized successfully')
        "
        
    - name: Run traffic data collection
      env:
        TOMTOM_API_KEY: ${{ secrets.TOMTOM_API_KEY }}
      run: |
        echo "Starting data collection at $(date)"
        python -c "
        import sys
        import traceback
        from src.api.tomtom_client import TomTomClient
        from src.database.models import SessionLocal
        from src.database.operations import save_route_info
        from src.config import ROUTES
        import shutil
        from datetime import datetime
        import pandas as pd
        import sqlite3
        import os

        try:
            def collect_data():
                client = TomTomClient()
                db = SessionLocal()
                try:
                    for route in ROUTES:
                        print(f'Collecting data for route: {route[\"name\"]}')
                        route_info = client.get_route_info(
                            from_coords=route['from_coords'],
                            to_coords=route['to_coords']
                        )
                        if route_info:
                            save_route_info(
                                db=db,
                                route_data=route_info,
                                from_coords=route['from_coords'],
                                to_coords=route['to_coords']
                            )
                            db.commit()  # Commit after each successful save
                            print(f'Successfully saved route data for {route[\"name\"]}')
                        else:
                            print(f'Failed to get route info for {route[\"name\"]}')
                except Exception as e:
                    db.rollback()
                    raise e
                finally:
                    db.close()

            # Collect new data
            print('Starting data collection...')
            collect_data()
            print('Data collection completed')
            
            # Create timestamped backup
            timestamp = datetime.now().strftime('%Y%m%d_%H%M')
            backup_db = f'backups/routes_{timestamp}.db'
            shutil.copy2('database/routes.db', backup_db)
            print(f'Database backup created at {backup_db}')
            
            # Export to CSV
            conn = sqlite3.connect('database/routes.db')
            df = pd.read_sql_query('SELECT * FROM route_info', conn)
            csv_file = f'backups/routes_{timestamp}.csv'
            df.to_csv(csv_file, index=False)
            conn.close()
            print(f'CSV export created at {csv_file}')
            
            # Print current database stats
            conn = sqlite3.connect('database/routes.db')
            cursor = conn.cursor()
            count = cursor.execute('SELECT COUNT(*) FROM route_info').fetchone()[0]
            latest = cursor.execute('SELECT MAX(timestamp) FROM route_info').fetchone()[0]
            conn.close()
            print(f'Current database status:')
            print(f'Total records: {count}')
            print(f'Latest record timestamp: {latest}')
            
            print('All operations completed successfully')
            sys.exit(0)
        except Exception as e:
            print('Error occurred:')
            print(str(e))
            print('Traceback:')
            traceback.print_exc()
            sys.exit(1)
        "
        echo "Completed data collection at $(date)"
        
    - name: Upload database
      if: always()  # Try to upload even if previous step failed
      uses: actions/upload-artifact@v4
      with:
        name: route-data
        path: |
          database/routes.db
          backups/*
        retention-days: 7 