name: Traffic Monitor

on:
  schedule:
    - cron: '*/5 * * * *'  # Run every 5 minutes
  workflow_dispatch:  # Manual trigger
    inputs:
      debug_enabled:
        type: boolean
        description: 'Run the workflow with debug logging'
        required: false
        default: false

permissions:
  contents: read
  actions: write

jobs:
  collect-traffic-data:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'schedule'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Set up fresh database
      run: |
        mkdir -p database backups logs
        # Always start with a fresh database
        python -c "
        from src.database.models import Base, engine
        import os
        
        # Remove existing database if it exists
        if os.path.exists('database/routes.db'):
            os.remove('database/routes.db')
        
        # Create new database with schema
        Base.metadata.create_all(engine)
        print('Fresh database created with schema')
        "
        
    - name: Try to restore previous data
      run: |
        # Download previous artifact (if it exists)
        python -c "
        import sqlite3
        import shutil
        import os
        
        def merge_databases():
            try:
                # Connect to the new (empty) database
                main_conn = sqlite3.connect('database/routes.db')
                main_cursor = main_conn.cursor()
                
                # Try to copy data from previous database
                if os.path.exists('previous-data/database/routes.db'):
                    prev_conn = sqlite3.connect('previous-data/database/routes.db')
                    prev_cursor = prev_conn.cursor()
                    
                    # Get all records from previous database
                    prev_cursor.execute('SELECT * FROM route_info')
                    records = prev_cursor.fetchall()
                    
                    if records:
                        # Get column names
                        prev_cursor.execute('PRAGMA table_info(route_info)')
                        columns = [col[1] for col in prev_cursor.fetchall()]
                        
                        # Prepare insert statement
                        placeholders = ','.join(['?' for _ in columns])
                        insert_sql = f'INSERT INTO route_info VALUES ({placeholders})'
                        
                        # Insert all records
                        main_cursor.executemany(insert_sql, records)
                        main_conn.commit()
                        print(f'Restored {len(records)} records from previous database')
                    
                    prev_conn.close()
                else:
                    print('No previous database found to restore')
                
                # Verify current record count
                count = main_cursor.execute('SELECT COUNT(*) FROM route_info').fetchone()[0]
                print(f'Current database has {count} records')
                
                main_conn.close()
                
            except Exception as e:
                print(f'Error during database merge: {str(e)}')
                print('Continuing with fresh database')
        
        merge_databases()
        "
        
    - name: Run traffic data collection
      env:
        TOMTOM_API_KEY: ${{ secrets.TOMTOM_API_KEY }}
      run: |
        echo "Starting data collection at $(date)"
        python -c "
        import sys
        import traceback
        from src.api.tomtom_client import TomTomClient
        from src.database.models import SessionLocal
        from src.database.operations import save_route_info
        from src.config import ROUTES
        import shutil
        from datetime import datetime
        import pandas as pd
        import sqlite3
        import os

        try:
            def collect_data():
                client = TomTomClient()
                db = SessionLocal()
                success_count = 0
                try:
                    for route in ROUTES:
                        print(f'Collecting data for route: {route[\"name\"]}')
                        route_info = client.get_route_info(
                            from_coords=route['from_coords'],
                            to_coords=route['to_coords']
                        )
                        if route_info:
                            save_route_info(
                                db=db,
                                route_data=route_info,
                                from_coords=route['from_coords'],
                                to_coords=route['to_coords']
                            )
                            db.commit()  # Commit after each successful save
                            success_count += 1
                            print(f'Successfully saved route data for {route[\"name\"]}')
                        else:
                            print(f'Failed to get route info for {route[\"name\"]}')
                except Exception as e:
                    db.rollback()
                    raise e
                finally:
                    db.close()
                return success_count

            # Collect new data
            print('Starting data collection...')
            records_added = collect_data()
            print(f'Data collection completed. Added {records_added} new records')
            
            # Create timestamped backup
            timestamp = datetime.now().strftime('%Y%m%d_%H%M')
            backup_db = f'backups/routes_{timestamp}.db'
            shutil.copy2('database/routes.db', backup_db)
            print(f'Database backup created at {backup_db}')
            
            # Export to CSV
            conn = sqlite3.connect('database/routes.db')
            df = pd.read_sql_query('SELECT * FROM route_info', conn)
            csv_file = f'backups/routes_{timestamp}.csv'
            df.to_csv(csv_file, index=False)
            conn.close()
            print(f'CSV export created at {csv_file}')
            
            # Print current database stats
            conn = sqlite3.connect('database/routes.db')
            cursor = conn.cursor()
            count = cursor.execute('SELECT COUNT(*) FROM route_info').fetchone()[0]
            latest = cursor.execute('SELECT MAX(timestamp) FROM route_info').fetchone()[0]
            conn.close()
            print(f'Current database status:')
            print(f'Total records: {count}')
            print(f'Latest record timestamp: {latest}')
            
            print('All operations completed successfully')
            sys.exit(0)
        except Exception as e:
            print('Error occurred:')
            print(str(e))
            print('Traceback:')
            traceback.print_exc()
            sys.exit(1)
        "
        echo "Completed data collection at $(date)"
        
    - name: Download previous artifact
      continue-on-error: true
      uses: actions/download-artifact@v4
      with:
        name: route-data
        path: previous-data
        
    - name: Upload database
      uses: actions/upload-artifact@v4
      with:
        name: route-data
        path: |
          database/routes.db
          backups/*
        retention-days: 90  # Increased retention period to 90 days 